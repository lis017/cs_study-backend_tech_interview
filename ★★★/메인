직렬화시 주의점
메모리에 로딩된 것만 직렬화 가능
LAZY는 참조라서 직렬화하면 LazyInitializationException 오류남
-----------
@Async가 뭐죠?
-> Spring에서 메서드를 별도의 스레드에서 비동기로 실행하여, 
호출한 스레드를 즉시 반환시키는 기능(동기 호출의 흐름을 반환하고, Async부분은 비동기로 천천히 진행한다)
->(심화)
Spring의 @Async는 프록시 기반 AOP로 메서드 호출을 가로채고, 
실제실행은 ThreadPool에서 관리되는 별도 스레드에서 처리됩니다.
따라서 내부 메서드 호출에서는 동작x

@Async 왜쓰죠?
-> 시간 오래 걸리지만 즉시 결과가 필요없는 작업에 사용
 .사용자 요청은 빠르게 응답
 .실제 작업은 백그라운드 처리

@Async 단점은?
-> 예외 전파와 트랜잭션 관리가 복잡해질 수 있음

@Async사용시 주의점
-> ThreadPool설정을 하지않으면 서버안정성에 문제
-> 실무에선 ThreadPoolTaskExecutor 필수
(안하면 쓰레드 무한증식 -> 서버터짐)
(쓰레드 개수와 큐를 제한하는것.)
@주의점2
-> 기본 트랜잭션된 함수내에서 Async쓰면 async함수는 트랜잭션 포함안됨 / async어노테이션 바로위or아래에 @Tracsactional 써야 적용됨
@주의점3
-> 예외발생시
@Async는 예외가 호출부로 전파되지 않기 때문에
AsyncUncaughtExceptionHandler로 로그·알림을 보장하거나,
중요 로직은 CompletableFuture로 예외를 명시적으로 처리해야함

같은 클래스 내부에서 @Async 호출하면?
-> X. 비동기 안됨.
->이유: 프록시 안거침 / 자기자신호출(self-invocation)
(꼭 다른클래스에서 호출해야함(bean간 호출))
(프록시란? : 실제 객체 앞에 끼워진 '대리객체'
/ Spring은 이 프록시를 통해서만 @Async, @Transactional, @Cacheable 같은 기능을 적용합니다.)

@Async 반환 타입
-> CompletableFuture<T> / 추천  (T는 String등 타입)
void / 결과 못 받음

비동기 할떄, 왜 @Async썼죠?
->해당 작업은 요청 흐름과 강하게 결합될 필요가 없는 후처리 작업이었고,
구현 복잡도를 낮추면서 **응답 지연을 줄이기 위해 @Async를 선택했습니다.
대규모 I/O나 고부하 환경이었다면 WebClient나 메시지 큐를 고려했을 것입니다.

비동기 처리방법 어떤것들있죠?
-> @Async (간단한 백그라운드 작업)
CompletableFuture (비동기 + 결과 처리)
WebClient(대규모 외부 API 호출)
메시지 큐 (Kafka)(대규모 트래픽 이벤트)(데이터 모으기)
@Scheduled (스케줄링)(통계 집계 / 로그 정리)
Spring Batch(수만~수백만 건 데이터 처리)(데이터 처리)

webclient썼으면서, 왜 굳이 Async로? 재사용하면 안됐나?
-> WebClient쓰면 upsert로직은 비동기안됨.
-> 업무처리 분리 개념은 Async로 충분. / 대용량되면 kafka / batch로.

Thread 안전성 문제가 뭐죠?
->여러 스레드가 동시에 같은 자원(변수, 객체, DB 상태 등)에 접근할 때
실행 순서에 따라 결과가 달라지거나 데이터 불일치가 발생하는 문제

Thread 안전성 문제는 해결했는가?
->1.@Async 메서드를 무상태(stateless)로 유지하고,            //무상태(stateless): 비동기 메서드 내부에 “공유되는 상태값”을 두지 않았다는 뜻
파라미터 기반으로만 동작하도록 구성하여
스레드 간 상태 공유로 인한 문제는 발생하지 않도록 설계
->2.애플리케이션 레벨에서 공유 객체를 직접 수정하지 않고,
데이터 변경은 DB에 위임하는 구조로 설계해
기본적인 JVM레벨의 쓰레드 안전성은 확보한 상태
(ex)repository.함수 이걸로 데이터 변환했던것)
(공유객체 수정하지않았다. 뜻은?
-> 클래스 필드 안쓰고 매개변수 쓰고 데이터변경은 repository를 사용->db위임)
(db에 위임하면 왜 안전?
-> db가 원래 동시에 여러 요청이와도 깨지지않게 설계
+ 충돌시 db가 락.롤백.차단 수행)
(향후)동시에 동일 데이터에 대한 upsert가 발생할 수 있는 경우를 대비해서는,
향후 unique constraint나 @Transactional 기반의 정합성 보완이 필요하다고 인지하고 있습니다.
(unique constraint: db에서 데이터 강제 중복금지 / @Transactional: insert후 update하는데 insert하고, update전에 예외발생시 정합성 깨짐. 그걸 보완)
-------------------------------
log.info가 운영에서 왜 도움됨?
-> 운영환경에서 print못봄.
로그는 볼수있음
과정 하나하나 log를 남기면 
그걸 기반으로 원인파악 빠르게 가능.
->무중단 운영시에도 파악가능
->운영 가시성(Observability)을 확보하는 핵심수단

단점이나 주의할 점
로그 과다 발생: 대용량 데이터를 모두 info 레벨로 기록하면 로그가 방대해져 디스크 용량이나 성능에 부담이 생길 수 있습니다.
민감 정보 유출 가능: 로그에 중요한 데이터가 포함되면 보안 이슈가 발생할 수 있습니다.
성능 영향: 지나치게 상세한 로그는 IO를 증가시켜 처리 속도를 느리게 만들 수 있습니다.

이런 단점을 어떻게 해결했나요?
적재 완료 건수, 성공/실패 상태만 기록
민감정보는 제가 했을떈 없었음. 있다면 마스킹처리 고려
성능영향도 제가 한건 너무 작은 log라서, 추후 많은로그를 관리해야한다면 
로그 레벨을 적절히 분리(info, warn, error)하여 운영 환경에서 필요한 정보만 모니터링하도록 할 생각

log.info 대신 다른 방법도 있을까요?
-모니터링 전용 시스템 활용: Prometheus, Grafana로 메트릭 수집 후 시각화
-비동기 로그 수집: ELK 스택(Logstash + Elasticsearch + Kibana) 활용
-다만, 간단한 운영 가시성을 위해 info 로그 기록만으로도 충분히 개선 효과를 확인할 수 있었습니다.
------------------------------------------------
QueryDSL이 뭐죠?
->자바 코드로 SQL을 타입 세이프하게 작성할 수 있도록 도와주는 쿼리 빌더 라이브러리
->(심화) QueryDSL은 타입 세이프한 자바 코드 기반 쿼리 작성으로, 복잡한 동적 조회를 안전하게 처리하기 위한 기술

QueryDSL 장점?
-> JPQL과 달리 컴파일 시점에 오류를 잡을 수 있어 안정성이 높음.
->동적 쿼리를 가독성 있게 작성가능

QueryDSL. 언제써야하죠?
->조건이 많은 조회 로직이나 검색 기능에

QueryDSL. 왜썼죠?
->공휴일 조회 기능을 만들었을떄, 연도와 국가 코드가 optional한 조회 조건이어서 where 절이 동적으로 변하는 구조였고,
조건과 정렬이 늘어날 가능성을 고려해 JPQL 문자열 방식보다 조건 확장과 유지보수에 유리한 QueryDSL을 선택했습니다.”
(구체적으로 어디가 동적이었나요?)
->“연도와 국가 코드가 optional이라
null일 경우 조건에서 자동 제외되도록
where 조건을 분리해서 구성했습니다.”
(JPQL로도 가능하지 않나요?)
->“가능하지만 문자열 기반이라
조건이 늘어날수록 가독성과 유지보수가 떨어져
QueryDSL을 선택했습니다.”

QueryDSL. 어떻게 사용했죠?
-> 공휴일 조회시
year, countryCode 같은 조건을 null 여부에 따라 분리한 Boolean 조건으로 구성한 뒤,
where() 절에 조합해서 사용했습니다.”
->(추가 한다면)
“또한 Pageable의 정렬 정보를 받아
정렬 대상 필드에 따라 OrderSpecifier를 동적으로 생성해
페이징과 정렬까지 한 번에 처리했습니다.”

QueryDSL말고 다른기술 없었나?
->“JPQL, 메서드 쿼리, Specification을 검토했고
동적 쿼리 확장성과 타입 안정성 측면에서
QueryDSL이 가장 적합해 선택했습니다.”
{
(참고)
JPQL: ❌ 타입 안정성 ❌
❌ 동적 쿼리 가독성 낮음
메서드 쿼리: ❌ 확장성 낮음
Specification:정렬·페이징·복잡한 조건을 함께 다루기에는
가독성이 떨어짐
}

QueryDSL 단점은?
->“엔티티 변경 시 Q 클래스가 다시 생성되어야 하고,
빌드 설정이나 IDE 환경에 따라
초기 세팅과 관리 비용이 발생합니다.”
->단순 CRUD에는 과한 선택일 수 있음
“조건이 단순한 조회의 경우
메서드 쿼리나 JPQL이 더 간결할 수 있어
모든 쿼리에 무조건 적용하는 것은 오히려 복잡도를 높일 수 있습니다.”

QueryDSL사용시 주의점은?
->“QueryDSL은 편리하지만, 성능(N+1, fetch join), 페이징 처리, 동적 쿼리 복잡도 관리를 특히 주의해서 사용해야 합니다.”

주의점 고려해서 예방한것?
->“QueryDSL 사용 시 주의사항 중
동적 조건 관리와 페이징 쿼리 안정성은 실제로 고려했습니다.
조건은 null-safe 방식으로 분리했고,
페이징 조회에서는 fetch join을 배제하고 count 쿼리를 분리해
성능 이슈를 피했습니다.”
->(미래)
“현재 요구사항 범위에서는 안정적으로 동작하도록 설계했고,
트래픽이나 데이터 규모가 커질 경우를 대비해
N+1, 쿼리 복잡도, 비동기 정합성 부분은
추후 개선 포인트로 인지하고 있습니다.”

타입안전(Type-safe) 뜻
->컴파일 시점(실행전에)에 오류를 잡아준다

QueryDSL은 왜 타입안전(Type-safe)?
-> JPQL은 문자열 기반이라 런타임 오류 위험이 있는데,
QueryDSL은 Q 클래스를 통해 필드와 타입을 컴파일 타임에 검증해서
타입 안전한 쿼리를 작성할 수 있습니다.”
------------------------------------------------
JPQL이뭐죠?
->JPQL은 엔티티 기준으로 작성하고, 실행 시 SQL로 변환되는 JPA 전용 쿼리 언어입니다.”
------------------------------------------------
트랜잭션이 뭐죠?”
트랜잭션은 여러 DB 작업을 하나의 논리적 작업 단위로 묶어서,
모두 성공하거나 모두 실패하도록 보장하는 개념입니다.
Spring에서는 주로 @Transactional을 통해 선언적으로 관리합니다.

“왜 트랜잭션이 필요한가요?”
데이터 변경 중 중간에 예외가 발생했을 때,
일부만 반영되는 정합성 깨짐을 방지하기 위해 필요합니다.
특히 삭제나 업데이트처럼 상태를 바꾸는 작업에서는 필수적입니다.

TransactionRequiredException어떻게 해결했나요?”
delete 함수를 호출하는 서비스 레이어에
@Transactional을 추가해서
예외를 해결했고, 동시에 원자성도 확보했습니다.
이유: “Spring의 트랜잭션은 프록시 기반 AOP로 구현되어 있어서,
외부 빈에서 호출되어 프록시를 거칠 때만 트랜잭션이 적용됩니다.
같은 클래스 내부 호출은 프록시를 우회하기 때문에 트랜잭션이 동작하지 않습니다.”


★단점이나 비용은 없나요?”
트랜잭션은 DB 락을 잡을 수 있어서
범위가 크거나 오래 유지되면 성능 저하가 발생할 수 있습니다.
그래서 꼭 필요한 범위에만 사용하는 게 중요합니다.

“트랜잭션 사용할 때 주의점은?”
너무 넓은 범위로 잡지 않기
트랜잭션 안에서 외부 API 호출 같은 느린 작업 피하기
@Transactional이 프록시 기반이라
같은 클래스 내부 호출에서는 적용 안 될 수 있다는 점
유스케이스 단위로 묶는게 좋다.

그 주의점을 실제로 어떻게 해결했나요?
“조회 로직은 트랜잭션 없이 처리했고, 삭제/저장 로직은 Service에서 @Transactional로 감싸
최소한의 범위에서 트랜잭션을 관리했습니다.
향후 필요 시, delete 전에 조회를 별도로 분리해 트랜잭션 범위를 더 줄일 수 있습니다.”
(왜 조회후삭제? -> 둘다 null이면 테이블삭제나 삭제대상명확화를 위해)
------------------------------------------------
JUnit5와 SpringBootTest란?
JUnit5: 자바 표준 단위 테스트 프레임워크의 최신 버전으로, 테스트 라이프사이클 제어, 조건부 실행, 파라미터화된 테스트 등을 지원합니다.

SpringBootTest: 스프링 부트 환경을 통째로 로드하여 통합 테스트를 할 수 있는 어노테이션입니다.
실제 애플리케이션 컨텍스트를 로드하므로, 의존성 주입, 빈 초기화 등 스프링 환경 그대로 테스트 가능합니다.

WebClient로 외부 API를 호출할 때 테스트는 어떻게 하셨나요?
WebClient는 비동기 HTTP 클라이언트로, 별도의 Entity 없이도 외부 API를 호출할 수 있습니다.
제 코드에서는 NagerApiClient를 통해 실제 외부 API를 호출하고, JUnit5와 @SpringBootTest 조합으로 통합 테스트를 수행했습니다.
테스트에서는 호출 결과를 확인하고, 예외 발생 여부와 응답 데이터 구조를 검증했습니다.
필요할 경우 MockWebServer를 활용해 외부 API를 모킹하여 네트워크 환경에 영향을 받지 않고 테스트할 수도 있습니다.

통합 테스트 진행 시 주의할 점과 해결한 경험이 있나요?
“테스트를 진행하며 외부 API 의존, 컨텍스트 로딩 시간 증가, 테스트 간 상태 공유 등 주의점.
테스트간 상태공유는 하지않게 설계해서 이부분은 문제없이함.
추후 필요할 경우
MockWebServer, WireMock, 테스트용 DB, @Transactional 롤백 등을 활용해 테스트 격리를 보장하고 속도 문제를 줄일 수 있습니다.”
------------------------------------------------
Docker 멀티 스테이지 빌드가 뭐죠?
->Docker 멀티 스테이지 빌드는
빌드용 이미지와 실행용 이미지를 분리해서,
최종 이미지에는 실행에 필요한 결과물만 포함하는 방식입니다.
-예를 들어 Java 프로젝트의 경우
Maven/Gradle이 설치된 이미지에서 빌드만 수행하고,
최종 단계에서는 JRE만 있는 경량 이미지로 결과물만 복사합니다.

왜 멀티 스테이지를 사용했나요? (가장 중요)
-> 가장 큰 이유는 이미지 경량화와 보안 강화입니다.
-빌드 도구(Maven, Gradle), 소스코드, 테스트 리소스가
최종 이미지에 포함되지 않기 때문에
이미지 크기가 줄고,
공격 표면도 함께 줄어드는 장점이 있습니다.

실제로 어떻게 작성했나요? (구조 설명)
일단 평범한 image만들듯 빌드해서 jar파일 만들고, 새로 이미지 만들어서 만들어둔 jar파일 포함. 
그러므로 빌드 도구와 소스코드등은 자연스레 이미지사용에서 제외됨.
실행에 필요한 최소한의 파일만 지님.
그러면 실행용이미지만 사용됨.

장점은 뭐라고 생각하나요?
이미지 크기 감소 → 배포 및 Pull 속도 개선
빌드 도구 미포함 → 보안 위험 감소
역할 분리 → Dockerfile 가독성 향상
CI/CD 파이프라인에 적합

단점이나 불편한 점도 있지 않나요?
디버깅 시 빌드 단계와 실행 단계가 분리돼 있어서
문제 원인을 추적하기가 단일 스테이지보다 어려울 수 있습니다.

멀티 스테이지 사용할 때 주의점은?
-필요한 파일만 최종 이미지로 복사하는 것
-빌드 캐시가 깨지지 않도록
의존성 파일과 소스 복사 순서를 신경 써야 한다는 점입니다.

주의점 해결했나요?
-> “멀티스테이지를 적용하면서
빌드 도구와 소스코드가 최종 이미지에 포함되지 않도록 했고,
결과적으로 이미지 크기와 보안 측면을 개선했습니다.
-다만 의존성 캐시 최적화까지는 적용하지 못했고,
추후 build.gradle등 의존성먼저 복사후, 코드복사 방식처럼. 캐시최적화가 필요하다는 문제는 인식중입니다.

용량 줄어든거 어떻게 측정했죠?
-> “싱글 스테이지로 빌드한 이미지와
멀티스테이지 적용 후 이미지를 각각 빌드한 뒤
docker images 명령어로 SIZE를 비교했습니다.”
------------------------------------------------
외부 API가 뭐죠?
-> 내가 만든 서버가 아닌 다른회사·서비스가 제공하는 기능·데이터를 HTTP요청으로 사용하는것
-> 예시: 공휴일 / 결제(카카오페이 등) / 로그인(카카오 소셜로그인) / 지도(카카오맵) API

외부 API 왜 썼죠? 왜 쓰죠?
->외부API사용경험 필요해서
-> 직접 구현하기 어려운 기능을 신뢰성 있게 재사용
최신 데이터(결제 상태, 공휴일 등)를 외부에서 제공받기 위함

외부API사용시 백엔드로서 생각(걱정, 고려)해볼점
->네트워크 지연·실패 가능성 있음
->타임아웃, 재시도, 예외 처리 필요
동기 호출 시 성능 영향 → @Async, 캐싱 등으로 보완
{
타임아웃: 외부 API가 응답을 안 주면 스레드가 계속 대기 → 서버 장애 / 몇초까지 기다리고 신호안오면 실패처리 / 지연대응
재시도: 몇초있다가 몇번만 재시도 / 무한x / 실패대응
예외처리: 캐시데이터 사용 / 현재사용불가 응답 / 기본값 반환 / 장애전파 차단
  (캐시는 단순한 성능 최적화 수단이 아니라,
  **외부 의존성 장애 시에도 서비스를 유지하기 위한 회복 전략(fallback)**으로 사용했습니다.)
  (하루나 한시간정도 데이터가 캐시에 남아있고, 일정시간 재사용 하는것
}

본인이 외부API사용하며 그런 단점에 대비한것이 있는가?
->외부 API 지연이 사용자 응답에 영향 주지 않도록 최근데이터 응답후, @Async를 써서 비동기 백그라운드 upsert 처리 / 응답지연회피
----------------------------------------------
Spring Data JPA Custom Repository가 뭔가요?
-> 기본 Repository 인터페이스로 해결하기 어려운
복잡한 조회나 동적 쿼리를 구현하기 위해
개발자가 직접 구현체를 만들어 확장하는 패턴입니다.

왜 기본 JpaRepository로 안 하고 Custom Repository를 썼나요?
->단순 CRUD는 JpaRepository로 충분했지만,
동적 조건, 조인, 성능 튜닝이 필요한 조회는
메서드 네이밍이나 @Query로 관리하기 어렵다고 판단했습니다.
그래서 조회 로직을 분리하고 유지보수를 위해 Custom Repository를 사용했습니다.

Custom Repository 안에서는 주로 뭘 사용했나요?
->복잡한 조건 조합과 타입 안정성을 위해 QueryDSL을 사용했습니다.
특히 동적 where 절과 페이징 처리에 유리했습니다.
(“JPQL은 페이징 시 content 쿼리와 count 쿼리를 문자열로 따로 관리해야 해서 오류가 많지만,
QueryDSL은 조건 객체를 재사용할 수 있어서 페이징 정합성과 유지보수성이 개선됩니다.”)

@Query로도 가능한데 굳이 Custom Repository 쓴 이유는?
->@Query는
쿼리가 길어지면 가독성이 떨어지고
동적 조건 처리에 한계가 있으며
문자열 기반이라 컴파일 타임 검증이 어렵습니다.
Custom Repository는 복잡한 로직을 코드로 분리할 수 있어서
테스트와 유지보수에 더 적합하다고 판단했습니다.

Custom Repository성능 측면에서 어떤 장점이 있었나요?
페이징 + 조건 필터링
필요한 컬럼만 조회
조인 구조 명확화
등을 Custom Repository에서 제어할 수 있습니다.

Custom Repository 사용 시 주의할 점은?
->Impl 네이밍 규칙 준수
트랜잭션 경계는 서비스 계층에서 관리                             //여러 Repository 호출을 하나의 트랜잭션으로 묶기 위함 
Repository에 비즈니스 로직이 섞이지 않도록 주의
(모두 직접 지켰음)
--------------------------------------
기초데이터 및 수행결과 분석, 해본 거 있나요?
-> 네, 있습니다.
저는 기능을 만들 때 기초 데이터를 먼저 확인하고, 그 결과를 기준으로 구조를 바꾼 경험이 있습니다.
1️⃣ 기초데이터 분석
외부 공휴일 API 기반 서비스에서
요청 시마다 외부 API를 호출하면 응답 지연이 발생하고,
반대로 DB에만 의존하면 데이터 신선도가 떨어진다는 문제를 확인했습니다.
실제로 로그를 통해 대량 API 호출 시 응답 시간이 늘어나는 것을 확인했습니다.
2️⃣ 수행 방식 결정
그래서 모든 요청마다 API를 호출하지 않고,
기존 데이터와 외부 API 데이터를 비교하는 구조로 바꿨고,
변경 여부 판단 후 변경된 데이터만 Upsert하도록 설계했습니다.
이 과정은 @Async 기반 비동기 백그라운드 처리로 분리했습니다.
3️⃣ 수행 결과 분석
그 결과
사용자는 즉시 응답을 받게 되었고
서버는 불필요한 외부 API 호출을 줄일 수 있었으며
데이터는 최신 상태를 유지할 수 있었습니다.
즉, 응답 속도·데이터 신선도·서버 부하를 동시에 개선했습니다.
4️⃣ 정리 멘트 (면접관 좋아함)
이 경험을 통해
저는 단순히 기능을 구현하는 것이 아니라,
기초 데이터 흐름을 먼저 보고 구조적으로 최적화하는 개발을 해봤다고 말씀드릴 수 있습니다.
-----------------------------------------------
서버 성능 검토 및 모니터링 경험 있나요?”
->네, 다만 저는 APM 지표 중심보다는,
로그·테스트·서비스 동작을 기반으로 성능 문제를 검토하고 개선한 경험을 가지고 있습니다.
->[성능 문제 모니터링및 검토 경험]
외부 API 지연 체감 및 log.info로 시간과 정상응답 측정
SpringBootTest로 일부 API 데이터를 호출해 정상 응답검증했고,
분석 결과, 문제는 외부 API 호출이 요청 흐름과 서버 기동에 직접 연결된 구조라고 판단
특히 대량 적재 시 지연이 커서, 동기 처리 구조가 병목이라고 판단했습니다.
그래서 외부 API upsert 로직을
@Async 기반 비동기 백그라운드 처리로 분리했고,
서버는 먼저 기동되고, 데이터는 백그라운드에서 적재되도록 구조를 변경
[DB 성능 검토 경험]
DB 쪽에서는 Page의 count 쿼리 문제를 인지해 Slice로 개선했고,
[빌드·배포 성능 검토]
multi-stage 빌드를 적용해 이미지 용량을 줄이고 빌드 산출물을 최소화
빌드 구조상 배포 속도와 보안이 개선되는 것은 명확히 인지하고 적용
[인프라 가용성 확인]
ECS Health Check는 컨테이너 강제 종료로 동작을 직접 검증해봤습니다.

“APM 안 썼는데, 한계는 뭐였나요?”
->log 기반 방식은 흐름 파악엔 충분했지만,
응답 시간, CPU·메모리 사용량 같은 지표를 지속적으로 수치화해서 보는 데는 한계가 있었습니다.
당시엔 구조 문제가 핵심이라 설계 개선에 집중했고,
->만약 APM을 붙였다면
비동기 전·후 응답 시간 변화
API별 처리 시간 분포
스레드 점유
같은 부분을 수치로 비교할 수 있었을 거라고 생각합니다.
이 부분은 제가 다음 단계에서 반드시 보완하고 싶은 영역입니다.
->APM은 ‘필수 도구’라기보다,
서비스 단계와 목적에 맞게 선택해야 하는 도구라고 생각하게 되었습니다.
지금은 APM 기반으로 성능을 수치화하는 단계로 성장하려고 생각 중입니다.
-----------------------------------------------
빅데이터 경험이 있나요?
하둡이나 스파크 같은 프레임워크를 직접 사용해본 경험은 없지만,
->외부 API에서 대량 데이터 수집
서버 기동 지연 체감
비동기 처리(@Async)로 구조 개선
로그(log.info)로 적재 상태 모니터링
->② 페이징 최적화 (Page → Slice)
count 쿼리로 인한 성능 문제 인지
Slice 방식으로 불필요한 count 제거
📌 이건 “데이터 규모가 커졌을 때의 성능 고려”
----------------------------------------------
Read-through cache + background refresh 구조 설명
->이건 실제 서비스에서 굉장히 많이 쓰는 패턴입니다.
자주 조회되는 데이터만 최신화
사용 안 되는 연도/국가는 굳이 API 호출 안 함
외부 API 비용 / 트래픽 / 지연 감소
(요청기반 부분동기화(on-demand sync))
->“전체 동기화는 배치나 스케줄링으로 분리하는 게 맞다고 보고 있습니다.”
------------------------------------------------
Builder패턴이 뭐죠?
->복잡한 생성자를 안전하고 가독성 좋게 만들기 위한 생성 패턴
->생성자 파라미터가 많을 때 / 객체를 불변(immutable)하게 만들고 싶을 때 사용

builder왜썼음?
->“엔티티 필드가 많아서 생성자 파라미터 가독성이 떨어졌고,
필드 누락이나 순서 실수를 방지하기 위해 builder 패턴을 사용했습니다.”
----------------------
java

Java collection 프레임워크 3가지
->  객체, 데이터들을 효율적으로 관리 할 수 있는 자료구조들이 있는 라이브러리
-> 자바 컬렉션 프레임워크의 주요 타입은 List, Set, Map입니다.
List는 순서를 보장하고 중복을 허용하는 자료구조로,
대표적으로 ArrayList, LinkedList가 있습니다.
Set은 중복을 허용하지 않고 순서는 보장하지 않으며,
HashSet, TreeSet 등이 있습니다.
Map은 Key-Value 구조로 데이터를 저장하며,
Key는 중복될 수 없고 Value는 중복이 가능합니다.
대표 구현체로 HashMap이 있습니다.
->Map은 Collection 인터페이스를 상속하진 않지만,
Collection에서 묶어서 얘기하며
Map 인터페이스는 구조상의 차이로 별도로 정의합니다.


